{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c1cadf9",
   "metadata": {},
   "source": [
    "<h1> Datos para probar las técnicas de analísis. </h1>\n",
    "\n",
    "<h2>Los pasos que intentare seguir para tener una metodología son: </h2>\n",
    "<br>\n",
    "<li>Paso cero: Extraccion de los datos, limpieza, reducción y eliminación en los casos que apliquen.</li>\n",
    "<li>Paso uno: Estandarizar, normalizar y/o reducir los datos.</li>\n",
    "<li>Paso dos: Codificar las variables categoricas.</li>\n",
    "<li>Paso tres: Escojer el médelo de machine learning que nos ayude a resolver el problema</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dcfbd7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import las primeras librerias que podriamos utilizar\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "455b2518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tamaño de la matriz\n",
      " (2197291, 15)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"PeopleTrain.csv\")\n",
    "print(\"\\nTamaño de la matriz\\n\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "573adba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2197291 entries, 0 to 2197290\n",
      "Data columns (total 15 columns):\n",
      " #   Column             Dtype \n",
      "---  ------             ----- \n",
      " 0   people_id          object\n",
      " 1   activity_id        object\n",
      " 2   date               object\n",
      " 3   activity_category  object\n",
      " 4   char_1             object\n",
      " 5   char_2             object\n",
      " 6   char_3             object\n",
      " 7   char_4             object\n",
      " 8   char_5             object\n",
      " 9   char_6             object\n",
      " 10  char_7             object\n",
      " 11  char_8             object\n",
      " 12  char_9             object\n",
      " 13  char_10            object\n",
      " 14  outcome            int64 \n",
      "dtypes: int64(1), object(14)\n",
      "memory usage: 251.5+ MB\n",
      "\n",
      "Tipos de variables: \n",
      "  None\n"
     ]
    }
   ],
   "source": [
    "#Revisar los tipos de variables y determinar si son correctas o las modifcamos.\n",
    "print(\"\\nTipos de variables: \\n \", df.info() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fdbd90e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cantidad de datos faltantes en porcentaje \n",
      " people_id             0.000000\n",
      "activity_id           0.000000\n",
      "date                  0.000000\n",
      "activity_category     0.000000\n",
      "char_1               92.826849\n",
      "char_2               92.826849\n",
      "char_3               92.826849\n",
      "char_4               92.826849\n",
      "char_5               92.826849\n",
      "char_6               92.826849\n",
      "char_7               92.826849\n",
      "char_8               92.826849\n",
      "char_9               92.826849\n",
      "char_10               7.173151\n",
      "outcome               0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCantidad de datos faltantes en porcentaje \\n\", df.isnull().sum()/df.shape[0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "870f37df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Las columnas que se remueven:\n",
      " ['char_1', 'char_2', 'char_3', 'char_4', 'char_5', 'char_6', 'char_7', 'char_8', 'char_9']\n",
      "\n",
      "Forma de la matriz:\n",
      " (2197291, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>people_id</th>\n",
       "      <th>activity_id</th>\n",
       "      <th>activity_date</th>\n",
       "      <th>activity_category</th>\n",
       "      <th>activity_type</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ppl_100</td>\n",
       "      <td>act2_1734928</td>\n",
       "      <td>2023-08-26</td>\n",
       "      <td>type 4</td>\n",
       "      <td>type 76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ppl_100</td>\n",
       "      <td>act2_2434093</td>\n",
       "      <td>2022-09-27</td>\n",
       "      <td>type 2</td>\n",
       "      <td>type 1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  people_id   activity_id activity_date activity_category activity_type  \\\n",
       "0   ppl_100  act2_1734928    2023-08-26            type 4       type 76   \n",
       "1   ppl_100  act2_2434093    2022-09-27            type 2        type 1   \n",
       "\n",
       "   outcome  \n",
       "0        0  \n",
       "1        0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hay que hacer una lista con las columnas que se van a remover.\n",
    "columnas_a_remover = [\"char_\"+str(x) for x in np.arange(1,10)]\n",
    "print(\"\\nLas columnas que se remueven:\\n\",columnas_a_remover)\n",
    "#Eliminar las columnas\n",
    "df = df.drop(columnas_a_remover, axis=1)\n",
    "#Se renobran las columnas para evitar un conflicto al unirse con el otro dataframe.\n",
    "df = df.rename(columns={\"date\":\"activity_date\",\"char_10\":\"activity_type\"})\n",
    "#Aquí interpolamos los datos que faltan en la columan char_10 con la moda.\n",
    "df[\"activity_type\"] = df[\"activity_type\"].fillna(df[\"activity_type\"].mode()[0])\n",
    "#Miremos la forma de la matriz con los cambios\n",
    "print(\"\\nForma de la matriz:\\n\",df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9cb52558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tamaño de la matriz\n",
      " (189118, 41)\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"People.csv\")\n",
    "print(\"\\nTamaño de la matriz\\n\", df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d275741e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 189118 entries, 0 to 189117\n",
      "Data columns (total 41 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   people_id  189118 non-null  object\n",
      " 1   char_1     189118 non-null  object\n",
      " 2   group_1    189118 non-null  object\n",
      " 3   char_2     189118 non-null  object\n",
      " 4   date       189118 non-null  object\n",
      " 5   char_3     189118 non-null  object\n",
      " 6   char_4     189118 non-null  object\n",
      " 7   char_5     189118 non-null  object\n",
      " 8   char_6     189118 non-null  object\n",
      " 9   char_7     189118 non-null  object\n",
      " 10  char_8     189118 non-null  object\n",
      " 11  char_9     189118 non-null  object\n",
      " 12  char_10    189118 non-null  bool  \n",
      " 13  char_11    189118 non-null  bool  \n",
      " 14  char_12    189118 non-null  bool  \n",
      " 15  char_13    189118 non-null  bool  \n",
      " 16  char_14    189118 non-null  bool  \n",
      " 17  char_15    189118 non-null  bool  \n",
      " 18  char_16    189118 non-null  bool  \n",
      " 19  char_17    189118 non-null  bool  \n",
      " 20  char_18    189118 non-null  bool  \n",
      " 21  char_19    189118 non-null  bool  \n",
      " 22  char_20    189118 non-null  bool  \n",
      " 23  char_21    189118 non-null  bool  \n",
      " 24  char_22    189118 non-null  bool  \n",
      " 25  char_23    189118 non-null  bool  \n",
      " 26  char_24    189118 non-null  bool  \n",
      " 27  char_25    189118 non-null  bool  \n",
      " 28  char_26    189118 non-null  bool  \n",
      " 29  char_27    189118 non-null  bool  \n",
      " 30  char_28    189118 non-null  bool  \n",
      " 31  char_29    189118 non-null  bool  \n",
      " 32  char_30    189118 non-null  bool  \n",
      " 33  char_31    189118 non-null  bool  \n",
      " 34  char_32    189118 non-null  bool  \n",
      " 35  char_33    189118 non-null  bool  \n",
      " 36  char_34    189118 non-null  bool  \n",
      " 37  char_35    189118 non-null  bool  \n",
      " 38  char_36    189118 non-null  bool  \n",
      " 39  char_37    189118 non-null  bool  \n",
      " 40  char_38    189118 non-null  int64 \n",
      "dtypes: bool(28), int64(1), object(12)\n",
      "memory usage: 23.8+ MB\n",
      "\n",
      "Tipos de variables: \n",
      "  None\n"
     ]
    }
   ],
   "source": [
    "#Revisar los tipos de variables y determinar si son correctas o las modifcamos.\n",
    "print(\"\\nTipos de variables: \\n \", df2.info() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c2a305bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cantidad de datos faltantes en porcentaje \n",
      " people_id    0.0\n",
      "char_1       0.0\n",
      "group_1      0.0\n",
      "char_2       0.0\n",
      "date         0.0\n",
      "char_3       0.0\n",
      "char_4       0.0\n",
      "char_5       0.0\n",
      "char_6       0.0\n",
      "char_7       0.0\n",
      "char_8       0.0\n",
      "char_9       0.0\n",
      "char_10      0.0\n",
      "char_11      0.0\n",
      "char_12      0.0\n",
      "char_13      0.0\n",
      "char_14      0.0\n",
      "char_15      0.0\n",
      "char_16      0.0\n",
      "char_17      0.0\n",
      "char_18      0.0\n",
      "char_19      0.0\n",
      "char_20      0.0\n",
      "char_21      0.0\n",
      "char_22      0.0\n",
      "char_23      0.0\n",
      "char_24      0.0\n",
      "char_25      0.0\n",
      "char_26      0.0\n",
      "char_27      0.0\n",
      "char_28      0.0\n",
      "char_29      0.0\n",
      "char_30      0.0\n",
      "char_31      0.0\n",
      "char_32      0.0\n",
      "char_33      0.0\n",
      "char_34      0.0\n",
      "char_35      0.0\n",
      "char_36      0.0\n",
      "char_37      0.0\n",
      "char_38      0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCantidad de datos faltantes en porcentaje \\n\", df2.isnull().sum()/df2.shape[0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "567f3abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forma de la matriz:\n",
      " (2197291, 46)\n"
     ]
    }
   ],
   "source": [
    "#Vamos a fucionar ambas matrices.\n",
    "df = df.merge(df2,on=[\"people_id\"],how=\"inner\")\n",
    "print(\"\\nForma de la matriz:\\n\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2a98677d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Los valores a predecir son :\n",
      " [0 1]\n",
      "\n",
      "Como estan distribuidas las variables a predecir: \n",
      " 0    55.60456\n",
      "1    44.39544\n",
      "Name: outcome, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLos valores a predecir son :\\n\",df[\"outcome\"].unique())\n",
    "print(\"\\nComo estan distribuidas las variables a predecir: \\n\", df[\"outcome\"].value_counts()/df.shape[0] *100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1849e09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distinct DataTypes:\n",
      " [dtype('O') dtype('int64') dtype('bool')]\n"
     ]
    }
   ],
   "source": [
    "#Revisando los tipos de datos con los que trabajaremos\n",
    "print(\"\\nDistinct DataTypes:\\n\", df.dtypes.unique() ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c649e759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nombre de las columnas que se categorizan como 1/0:\n",
      "          char_10  char_11  char_12  char_13  char_14  char_15  char_16  \\\n",
      "0           True    False    False     True     True    False     True   \n",
      "1           True    False    False     True     True    False     True   \n",
      "2           True    False    False     True     True    False     True   \n",
      "3           True    False    False     True     True    False     True   \n",
      "4           True    False    False     True     True    False     True   \n",
      "...          ...      ...      ...      ...      ...      ...      ...   \n",
      "2197286     True     True     True     True     True     True     True   \n",
      "2197287     True     True     True     True     True     True     True   \n",
      "2197288     True     True     True     True     True     True     True   \n",
      "2197289     True     True     True     True     True     True     True   \n",
      "2197290     True     True     True     True     True     True     True   \n",
      "\n",
      "         char_17  char_18  char_19  ...  char_28  char_29  char_30  char_31  \\\n",
      "0          False    False    False  ...     True    False     True     True   \n",
      "1          False    False    False  ...     True    False     True     True   \n",
      "2          False    False    False  ...     True    False     True     True   \n",
      "3          False    False    False  ...     True    False     True     True   \n",
      "4          False    False    False  ...     True    False     True     True   \n",
      "...          ...      ...      ...  ...      ...      ...      ...      ...   \n",
      "2197286     True     True     True  ...     True     True     True     True   \n",
      "2197287     True     True     True  ...     True     True     True     True   \n",
      "2197288     True     True     True  ...     True     True     True     True   \n",
      "2197289     True     True     True  ...     True     True     True     True   \n",
      "2197290     True     True     True  ...     True     True     True     True   \n",
      "\n",
      "         char_32  char_33  char_34  char_35  char_36  char_37  \n",
      "0          False    False     True     True     True    False  \n",
      "1          False    False     True     True     True    False  \n",
      "2          False    False     True     True     True    False  \n",
      "3          False    False     True     True     True    False  \n",
      "4          False    False     True     True     True    False  \n",
      "...          ...      ...      ...      ...      ...      ...  \n",
      "2197286     True    False     True     True     True     True  \n",
      "2197287     True    False     True     True     True     True  \n",
      "2197288     True    False     True     True     True     True  \n",
      "2197289     True    False     True     True     True     True  \n",
      "2197290     True    False     True     True     True     True  \n",
      "\n",
      "[2197291 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNombre de las columnas que se categorizan como 1/0:\\n\", df.select_dtypes(\"bool\"))\n",
    "#Convertir los valores\n",
    "for col in df.select_dtypes(\"bool\"):\n",
    "    df[col] = np.where(df[col] == True,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c0be2f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "people_id column has : 151295 distinct values\n",
      "activity_id column has : 2197291 distinct values\n",
      "activity_date column has : 411 distinct values\n",
      "activity_category column has : 7 distinct values\n",
      "activity_type column has : 6515 distinct values\n",
      "char_1 column has : 2 distinct values\n",
      "group_1 column has : 29899 distinct values\n",
      "char_2 column has : 3 distinct values\n",
      "date column has : 1196 distinct values\n",
      "char_3 column has : 43 distinct values\n",
      "char_4 column has : 25 distinct values\n",
      "char_5 column has : 9 distinct values\n",
      "char_6 column has : 7 distinct values\n",
      "char_7 column has : 25 distinct values\n",
      "char_8 column has : 8 distinct values\n",
      "char_9 column has : 9 distinct values\n"
     ]
    }
   ],
   "source": [
    "#Revisemos los distintos valores que se deberan recodificar\n",
    "for col in df.select_dtypes(\"object\"):\n",
    "    print(col + \" column has :\", str( len( df[col].unique())) + \" distinct values\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2123f8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WINDOW~1\\AppData\\Local\\Temp/ipykernel_7728/4134797014.py:6: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "  df[\"Week\"] = df[\"date\"].dt.week\n"
     ]
    }
   ],
   "source": [
    "#Convertir la variable date de object a datetime. Separar esas fechas por categoria mes, dia, etc..\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df[\"Year\"] = df[\"date\"].dt.year\n",
    "df[\"Month\"] = df[\"date\"].dt.month\n",
    "df[\"Quarter\"] = df[\"date\"].dt.quarter\n",
    "df[\"Week\"] = df[\"date\"].dt.week\n",
    "df[\"WeekDay\"] = df[\"date\"].dt.weekday\n",
    "df[\"Day\"] = df[\"date\"].dt.day\n",
    "\n",
    "#Vamos a quitar la columna de fecha por que no nos ayud al momento de entrenar la red.\n",
    "del(df[\"date\"])\n",
    "del(df[\"activity_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6f783544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  people_id activity_type   activity_id      group_1\n",
      "0   ppl_100       type 76  act2_1734928  group 17304\n",
      "1   ppl_100        type 1  act2_2434093  group 17304\n",
      "2   ppl_100        type 1  act2_3404049  group 17304\n",
      "3   ppl_100        type 1  act2_3651215  group 17304\n",
      "4   ppl_100        type 1  act2_4109017  group 17304\n",
      "   people_id  activity_type  activity_id  group_1\n",
      "0      100.0             76    1734928.0    17304\n",
      "1      100.0              1    2434093.0    17304\n",
      "2      100.0              1    3404049.0    17304\n",
      "3      100.0              1    3651215.0    17304\n",
      "4      100.0              1    4109017.0    17304\n"
     ]
    }
   ],
   "source": [
    "#Estas columnas se tienen que depurar para quedarnos con los datos numericos.\n",
    "print(df[[\"people_id\",\"activity_type\",\"activity_id\", \"group_1\"]].head())\n",
    "\n",
    "df.people_id = df.people_id.apply(lambda x:x.split(\"_\")[1])\n",
    "df.people_id = pd.to_numeric(df.people_id)\n",
    "\n",
    "df.activity_id = df.activity_id.apply(lambda x:x.split(\"_\")[1])\n",
    "df.activity_id = pd.to_numeric(df.activity_id)\n",
    "\n",
    "df.group_1 = df.group_1.apply(lambda x:x.split(\" \")[1])\n",
    "df.group_1 = pd.to_numeric(df.group_1)\n",
    "\n",
    "df.activity_type = df.activity_type.apply(lambda x:x.split(\" \")[1])\n",
    "df.activity_type = pd.to_numeric(df.activity_type)\n",
    "\n",
    "print(df[[\"people_id\",\"activity_type\",\"activity_id\", \"group_1\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "791dff3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Columns Name: activity_category\n",
      "************\n",
      "type 1 : 0\n",
      "type 2 : 1\n",
      "type 3 : 2\n",
      "type 4 : 3\n",
      "type 5 : 4\n",
      "type 6 : 5\n",
      "type 7 : 6\n",
      "\n",
      "\n",
      "Columns Name: char_1\n",
      "************\n",
      "type 1 : 0\n",
      "type 2 : 1\n",
      "\n",
      "\n",
      "Columns Name: char_2\n",
      "************\n",
      "type 1 : 0\n",
      "type 2 : 1\n",
      "type 3 : 2\n",
      "\n",
      "\n",
      "Columns Name: char_3\n",
      "************\n",
      "type 1 : 0\n",
      "type 10 : 1\n",
      "type 11 : 2\n",
      "type 12 : 3\n",
      "type 13 : 4\n",
      "type 14 : 5\n",
      "type 15 : 6\n",
      "type 16 : 7\n",
      "type 17 : 8\n",
      "type 18 : 9\n",
      "type 19 : 10\n",
      "type 2 : 11\n",
      "type 20 : 12\n",
      "type 21 : 13\n",
      "type 22 : 14\n",
      "type 23 : 15\n",
      "type 24 : 16\n",
      "type 25 : 17\n",
      "type 26 : 18\n",
      "type 27 : 19\n",
      "type 28 : 20\n",
      "type 29 : 21\n",
      "type 3 : 22\n",
      "type 30 : 23\n",
      "type 31 : 24\n",
      "type 32 : 25\n",
      "type 33 : 26\n",
      "type 34 : 27\n",
      "type 35 : 28\n",
      "type 36 : 29\n",
      "type 37 : 30\n",
      "type 38 : 31\n",
      "type 39 : 32\n",
      "type 4 : 33\n",
      "type 40 : 34\n",
      "type 41 : 35\n",
      "type 42 : 36\n",
      "type 44 : 37\n",
      "type 5 : 38\n",
      "type 6 : 39\n",
      "type 7 : 40\n",
      "type 8 : 41\n",
      "type 9 : 42\n",
      "\n",
      "\n",
      "Columns Name: char_4\n",
      "************\n",
      "type 1 : 0\n",
      "type 10 : 1\n",
      "type 11 : 2\n",
      "type 12 : 3\n",
      "type 13 : 4\n",
      "type 14 : 5\n",
      "type 15 : 6\n",
      "type 16 : 7\n",
      "type 17 : 8\n",
      "type 18 : 9\n",
      "type 19 : 10\n",
      "type 2 : 11\n",
      "type 20 : 12\n",
      "type 21 : 13\n",
      "type 22 : 14\n",
      "type 23 : 15\n",
      "type 24 : 16\n",
      "type 25 : 17\n",
      "type 3 : 18\n",
      "type 4 : 19\n",
      "type 5 : 20\n",
      "type 6 : 21\n",
      "type 7 : 22\n",
      "type 8 : 23\n",
      "type 9 : 24\n",
      "\n",
      "\n",
      "Columns Name: char_5\n",
      "************\n",
      "type 1 : 0\n",
      "type 2 : 1\n",
      "type 3 : 2\n",
      "type 4 : 3\n",
      "type 5 : 4\n",
      "type 6 : 5\n",
      "type 7 : 6\n",
      "type 8 : 7\n",
      "type 9 : 8\n",
      "\n",
      "\n",
      "Columns Name: char_6\n",
      "************\n",
      "type 1 : 0\n",
      "type 2 : 1\n",
      "type 3 : 2\n",
      "type 4 : 3\n",
      "type 5 : 4\n",
      "type 6 : 5\n",
      "type 7 : 6\n",
      "\n",
      "\n",
      "Columns Name: char_7\n",
      "************\n",
      "type 1 : 0\n",
      "type 10 : 1\n",
      "type 11 : 2\n",
      "type 12 : 3\n",
      "type 13 : 4\n",
      "type 14 : 5\n",
      "type 15 : 6\n",
      "type 16 : 7\n",
      "type 17 : 8\n",
      "type 18 : 9\n",
      "type 19 : 10\n",
      "type 2 : 11\n",
      "type 20 : 12\n",
      "type 21 : 13\n",
      "type 22 : 14\n",
      "type 23 : 15\n",
      "type 24 : 16\n",
      "type 25 : 17\n",
      "type 3 : 18\n",
      "type 4 : 19\n",
      "type 5 : 20\n",
      "type 6 : 21\n",
      "type 7 : 22\n",
      "type 8 : 23\n",
      "type 9 : 24\n",
      "\n",
      "\n",
      "Columns Name: char_8\n",
      "************\n",
      "type 1 : 0\n",
      "type 2 : 1\n",
      "type 3 : 2\n",
      "type 4 : 3\n",
      "type 5 : 4\n",
      "type 6 : 5\n",
      "type 7 : 6\n",
      "type 8 : 7\n",
      "\n",
      "\n",
      "Columns Name: char_9\n",
      "************\n",
      "type 1 : 0\n",
      "type 2 : 1\n",
      "type 3 : 2\n",
      "type 4 : 3\n",
      "type 5 : 4\n",
      "type 6 : 5\n",
      "type 7 : 6\n",
      "type 8 : 7\n",
      "type 9 : 8\n"
     ]
    }
   ],
   "source": [
    "#Vamos a codificar las variables categoricas\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "for col in df.select_dtypes(\"object\"):\n",
    "    print('\\n')\n",
    "    print('Columns Name: %s' %col)\n",
    "    print('************')\n",
    "    df[col] = df[[col]].apply(encoder.fit_transform)\n",
    "    for i in range(len(encoder.classes_)):\n",
    "        print(encoder.classes_[i],':', i)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "727b3bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for columna in df.select_dtypes(\"object\"):\n",
    "    print(\"\\nLa variable y sus categorias:\\n\", df[columna].value_counts() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "62a6206f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Las columnas de la matriz\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['people_id', 'activity_id', 'activity_category', 'activity_type',\n",
       "       'outcome', 'char_1', 'group_1', 'char_2', 'char_3', 'char_4', 'char_5',\n",
       "       'char_6', 'char_7', 'char_8', 'char_9', 'char_10', 'char_11', 'char_12',\n",
       "       'char_13', 'char_14', 'char_15', 'char_16', 'char_17', 'char_18',\n",
       "       'char_19', 'char_20', 'char_21', 'char_22', 'char_23', 'char_24',\n",
       "       'char_25', 'char_26', 'char_27', 'char_28', 'char_29', 'char_30',\n",
       "       'char_31', 'char_32', 'char_33', 'char_34', 'char_35', 'char_36',\n",
       "       'char_37', 'char_38', 'Year', 'Month', 'Quarter', 'Week', 'WeekDay',\n",
       "       'Day'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nLas columnas de la matriz\\n\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "93a800a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pero se van separar en una matriz x y un vector y\n",
      "\n",
      "\n",
      "Tamaño de la matriz sin la columna date\n",
      " (2197291, 49)\n",
      "\n",
      "Estas con las columnas de X\n",
      " Index(['people_id', 'activity_id', 'activity_category', 'activity_type',\n",
      "       'char_1', 'group_1', 'char_2', 'char_3', 'char_4', 'char_5', 'char_6',\n",
      "       'char_7', 'char_8', 'char_9', 'char_10', 'char_11', 'char_12',\n",
      "       'char_13', 'char_14', 'char_15', 'char_16', 'char_17', 'char_18',\n",
      "       'char_19', 'char_20', 'char_21', 'char_22', 'char_23', 'char_24',\n",
      "       'char_25', 'char_26', 'char_27', 'char_28', 'char_29', 'char_30',\n",
      "       'char_31', 'char_32', 'char_33', 'char_34', 'char_35', 'char_36',\n",
      "       'char_37', 'char_38', 'Year', 'Month', 'Quarter', 'Week', 'WeekDay',\n",
      "       'Day'],\n",
      "      dtype='object')\n",
      "\n",
      "Tamaño del vector a predecir\n",
      " (2197291, 1)\n",
      "\n",
      "Estas con las columnas de y\n",
      " Index(['outcome'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Separamos la matriz en variables para entrenas y el vecotor a predecir\n",
    "X = df.loc[:, ['people_id', 'activity_id', 'activity_category', 'activity_type',\n",
    "       'char_1', 'group_1', 'char_2', 'char_3', 'char_4', 'char_5',\n",
    "       'char_6', 'char_7', 'char_8', 'char_9', 'char_10', 'char_11', 'char_12',\n",
    "       'char_13', 'char_14', 'char_15', 'char_16', 'char_17', 'char_18',\n",
    "       'char_19', 'char_20', 'char_21', 'char_22', 'char_23', 'char_24',\n",
    "       'char_25', 'char_26', 'char_27', 'char_28', 'char_29', 'char_30',\n",
    "       'char_31', 'char_32', 'char_33', 'char_34', 'char_35', 'char_36',\n",
    "       'char_37', 'char_38', 'Year', 'Month', 'Quarter', 'Week', 'WeekDay','Day']] \n",
    "y = df.loc[:, [\"outcome\"]]\n",
    "print(\"\\nPero se van separar en una matriz x y un vector y\\n\") \n",
    "print(\"\\nTamaño de la matriz sin la columna date\\n\",  X.shape )\n",
    "print(\"\\nEstas con las columnas de X\\n\", X.columns)\n",
    "print(\"\\nTamaño del vector a predecir\\n\",  y.shape )\n",
    "print(\"\\nEstas con las columnas de y\\n\", y.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "57f86c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (1582048, 49)\n",
      "x_test: (439459, 49)\n",
      "x_val: (175784, 49)\n",
      "y_train: (1582048, 1)\n",
      "y_test: (439459, 1)\n",
      "y_val: (175784, 1)\n"
     ]
    }
   ],
   "source": [
    "#Dividamso los datos para su entremiento, validación y prueba.\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=2018)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=2018)\n",
    "print(\"x_train:\",x_train.shape)\n",
    "print(\"x_test:\",x_test.shape)\n",
    "print(\"x_val:\",x_val.shape)\n",
    "print(\"y_train:\",y_train.shape)\n",
    "print(\"y_test:\",y_test.shape)\n",
    "print(\"y_val:\",y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "95f64e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "24720/24720 [==============================] - 44s 2ms/step - loss: 381.1504 - accuracy: 0.6571 - val_loss: 1.1703 - val_accuracy: 0.6225\n",
      "Epoch 2/3\n",
      "24720/24720 [==============================] - 41s 2ms/step - loss: 0.6515 - accuracy: 0.6154 - val_loss: 0.6872 - val_accuracy: 0.5545\n",
      "Epoch 3/3\n",
      "24720/24720 [==============================] - 42s 2ms/step - loss: 0.6870 - accuracy: 0.5562 - val_loss: 0.6872 - val_accuracy: 0.5545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23d94479a30>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ahora si vamos a entrenar la matriz X.\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256,input_dim=x_train.shape[1],activation=\"relu\"))\n",
    "model.add(Dense(256,activation=\"relu\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\")) \n",
    "model.compile(optimizer=\"Adam\",loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train,y_train,validation_data=(x_val,y_val), epochs=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "43fd1662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "24720/24720 [==============================] - 42s 2ms/step - loss: 494.9026 - accuracy: 0.6351 - val_loss: 0.6522 - val_accuracy: 0.6146\n",
      "Epoch 2/2\n",
      "24720/24720 [==============================] - 41s 2ms/step - loss: 0.6841 - accuracy: 0.5624 - val_loss: 0.6872 - val_accuracy: 0.5545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23d94671610>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256,input_dim = x_train.shape[1],activation=\"relu\"))\n",
    "model.add(Dense(256,activation=\"relu\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.compile(optimizer=\"Adam\",loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train,y_train,validation_data=(x_val,y_val),epochs=2, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a1b2a7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "24720/24720 [==============================] - 30s 1ms/step - loss: 940.8928 - accuracy: 0.6781 - val_loss: 133.7059 - val_accuracy: 0.8245\n",
      "Epoch 2/2\n",
      "24720/24720 [==============================] - 28s 1ms/step - loss: 199.4964 - accuracy: 0.7361 - val_loss: 31.4522 - val_accuracy: 0.8045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23d947b2be0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512,input_dim=x_train.shape[1],activation=\"relu\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.compile(optimizer=\"Adam\",loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train,y_train,validation_data=(x_val,y_val),epochs=2, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6bb7359f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "24720/24720 [==============================] - 125s 5ms/step - loss: 322.7917 - accuracy: 0.6012 - val_loss: 0.6872 - val_accuracy: 0.5545\n",
      "Epoch 2/2\n",
      "24720/24720 [==============================] - 125s 5ms/step - loss: 0.7052 - accuracy: 0.5562 - val_loss: 0.6872 - val_accuracy: 0.5545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23d94ac9ac0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512,input_dim=x_train.shape[1],activation=\"relu\"))\n",
    "model.add(Dense(512,activation=\"relu\"))\n",
    "model.add(Dense(1,activation = \"sigmoid\"))\n",
    "model.compile(optimizer=\"Adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "model.fit(x_train,y_train,validation_data=(x_val,y_val),epochs=2, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33333304",
   "metadata": {},
   "source": [
    "<h2>Hay que intentar normalizar, estandarizar o centrar los datos para mirar sihay diferentes resultados.</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f76b6f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_val_scaled = scaler.transform(x_val)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3e652932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "24720/24720 [==============================] - 30s 1ms/step - loss: 0.2784 - accuracy: 0.8673 - val_loss: 0.2412 - val_accuracy: 0.8914\n",
      "Epoch 2/2\n",
      "24720/24720 [==============================] - 28s 1ms/step - loss: 0.2268 - accuracy: 0.8980 - val_loss: 0.2202 - val_accuracy: 0.9020\n",
      "13734/13734 [==============================] - 10s 698us/step - loss: 0.2188 - accuracy: 0.9024\n",
      "Metric  loss : 0.22\n",
      "Metric  accuracy : 0.9\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512,input_dim=x_train_scaled.shape[1],activation=\"relu\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.compile(optimizer=\"Adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "model.fit(x_train_scaled,y_train,validation_data=(x_val_scaled,y_val), epochs=2, batch_size=64)\n",
    "result = model.evaluate(x_test_scaled,y_test)\n",
    "\n",
    "for i in range(len(model.metrics_names)):\n",
    "    print(\"Metric \",model.metrics_names[i],\":\", str(round(result[i],2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "22848706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "24720/24720 [==============================] - 124s 5ms/step - loss: 0.2287 - accuracy: 0.8950 - val_loss: 0.1799 - val_accuracy: 0.9224\n",
      "Epoch 2/2\n",
      "24720/24720 [==============================] - 118s 5ms/step - loss: 0.1588 - accuracy: 0.9330 - val_loss: 0.1450 - val_accuracy: 0.9396\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23d94ccda00>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512,input_dim = x_train_scaled.shape[1],activation=\"relu\"))\n",
    "model.add(Dense(512,activation=\"relu\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.compile(optimizer=\"Adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "model.fit(x_train_scaled,y_train,validation_data=(x_val_scaled,y_val),epochs=2, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ff8aa784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "24720/24720 [==============================] - 358s 14ms/step - loss: 0.2285 - accuracy: 0.8948 - val_loss: 0.1749 - val_accuracy: 0.9235\n",
      "Epoch 2/2\n",
      "24720/24720 [==============================] - 373s 15ms/step - loss: 0.1563 - accuracy: 0.9335 - val_loss: 0.1449 - val_accuracy: 0.9394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23d94811fa0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1024,input_dim=x_train_scaled.shape[1],activation=\"relu\"))\n",
    "model.add(Dense(1024,activation = \"relu\"))\n",
    "model.add(Dense(1,activation = \"sigmoid\"))\n",
    "model.compile(optimizer = \"Adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "model.fit(x_train_scaled,y_train, validation_data=(x_val_scaled,y_val),epochs=2, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ad6e3dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "24720/24720 [==============================] - 128s 5ms/step - loss: 0.2294 - accuracy: 0.8947 - val_loss: 0.1775 - val_accuracy: 0.9239\n",
      "Epoch 2/5\n",
      "24720/24720 [==============================] - 129s 5ms/step - loss: 0.1589 - accuracy: 0.9327 - val_loss: 0.1489 - val_accuracy: 0.9383\n",
      "Epoch 3/5\n",
      "24720/24720 [==============================] - 129s 5ms/step - loss: 0.1343 - accuracy: 0.9447 - val_loss: 0.1297 - val_accuracy: 0.9478\n",
      "Epoch 4/5\n",
      "24720/24720 [==============================] - 130s 5ms/step - loss: 0.1205 - accuracy: 0.9510 - val_loss: 0.1223 - val_accuracy: 0.9510\n",
      "Epoch 5/5\n",
      "24720/24720 [==============================] - 130s 5ms/step - loss: 0.1111 - accuracy: 0.9551 - val_loss: 0.1145 - val_accuracy: 0.9544\n",
      "13734/13734 [==============================] - 23s 2ms/step - loss: 0.1139 - accuracy: 0.9547\n",
      "Metric  loss : 0.11\n",
      "Metric  accuracy : 0.95\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512,input_dim=x_train_scaled.shape[1],activation=\"relu\"))\n",
    "model.add(Dense(512,activation=\"relu\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.compile(optimizer=\"Adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "model.fit(x_train_scaled,y_train,validation_data=(x_val_scaled,y_val),epochs=5, batch_size=64)\n",
    "\n",
    "result = model.evaluate(x_test_scaled,y_test)\n",
    "for i in range(len(model.metrics_names)):\n",
    "    print(\"Metric \",model.metrics_names[i],\":\", str(round(result[i],2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4627bf57",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\WINDOW~1\\AppData\\Local\\Temp/ipykernel_7728/1863176358.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Model's Training & Validation loss across epochs\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epochs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'loss'"
     ]
    }
   ],
   "source": [
    "plt.plot(model.history.history['loss'])\n",
    "plt.plot(model.history.history['val_loss'])\n",
    "plt.title(\"Model's Training & Validation loss across epochs\")\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "56096d4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\WINDOW~1\\AppData\\Local\\Temp/ipykernel_7728/3936705732.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Model's Training & Validation Accuracy across epochs\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epochs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'acc'"
     ]
    }
   ],
   "source": [
    "plt.plot(model.history.history['acc'])\n",
    "plt.plot(model.history.history['val_acc'])\n",
    "plt.title(\"Model's Training & Validation Accuracy across epochs\")\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a73aabbf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\WINDOW~1\\AppData\\Local\\Temp/ipykernel_1812/4113851990.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LogRegKeras.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"LogRegKeras.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
